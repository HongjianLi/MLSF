{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pandas as ps\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def rmse(a, b):\n",
    "    return np.sqrt(np.sum((np.array(a)-np.array(b))**2)/len(a))\n",
    "\n",
    "def r2(a, b):\n",
    "    return 1 - np.sum((np.array(a)-np.array(b))**2)/np.sum((np.array(a)-np.mean(a))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_structure = [1.00000, 0.99900, 0.99800, 0.99700, 0.99600, 0.99500, 0.99000, 0.98500, 0.98000, 0.97500, 0.97000,\n",
    "                0.96500, 0.96000, 0.95500, 0.95000, 0.90000, 0.85000, 0.80000, 0.75000, 0.70000, 0.65000, 0.60000,\n",
    "                0.55000, 0.50000, 0.45000, 0.40000, 0.35000, 0.30000, 0.25000, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
    "\n",
    "# file paths should be changed to actual placement\n",
    "SS = ps.read_excel('Structure_Similarity.xls')\n",
    "train = ps.read_table('../../rawdata/training.tsv', index_col=0)\n",
    "test = ps.read_table('../../rawdata/test.tsv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search for the parameters. Different number of trees, tree depths and learning rates are tested. For each parameter, the calculations are run 10 times with different seeds and the mean performance (Rp, Rs and RMSE) is reported. Tests are run with the whole training set, performances are evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 \t 0.1 \t 200 \t 0.7763689273850372 \t 0.7717935647260697 \t 1.5040265442350667\n",
      "5 \t 0.1 \t 300 \t 0.7755995682118993 \t 0.7713458229774122 \t 1.5049448928051263\n",
      "5 \t 0.1 \t 400 \t 0.7686129276051524 \t 0.7635226020677394 \t 1.5233887609038261\n",
      "5 \t 0.1 \t 500 \t 0.7665571163040918 \t 0.7605502539437666 \t 1.5302884774129215\n",
      "5 \t 0.1 \t 600 \t 0.7649031409877578 \t 0.7594159694523636 \t 1.5334933766248604\n",
      "5 \t 0.1 \t 700 \t 0.7678806188718599 \t 0.7645290297070045 \t 1.5236237010593983\n",
      "5 \t 0.1 \t 800 \t 0.7665301062503582 \t 0.7616227949046751 \t 1.5276976437618457\n",
      "5 \t 0.1 \t 900 \t 0.7720345965091077 \t 0.769519978575648 \t 1.511525763922005\n",
      "5 \t 0.1 \t 1000 \t 0.7688298076329747 \t 0.7630745366308485 \t 1.5210519852647981\n",
      "5 \t 0.05 \t 200 \t 0.7857881664503452 \t 0.7794575310249783 \t 1.4980212583135615\n",
      "5 \t 0.05 \t 300 \t 0.7796434934494272 \t 0.7773251538663165 \t 1.5023544223686778\n",
      "5 \t 0.05 \t 400 \t 0.7848672956465554 \t 0.7812471223446172 \t 1.4853547806173588\n",
      "5 \t 0.05 \t 500 \t 0.7815419511608018 \t 0.7763998101294829 \t 1.4923108136279013\n",
      "5 \t 0.05 \t 600 \t 0.7868046608880294 \t 0.7825252862557045 \t 1.4762961513828232\n",
      "5 \t 0.05 \t 700 \t 0.7855526951441629 \t 0.7832809364362511 \t 1.4788729478161695\n",
      "5 \t 0.05 \t 800 \t 0.7794914865570941 \t 0.7774381210597243 \t 1.4944135530080562\n",
      "5 \t 0.05 \t 900 \t 0.7825755191271313 \t 0.7794408610809656 \t 1.4854811807239932\n",
      "5 \t 0.05 \t 1000 \t 0.7816343772998241 \t 0.7789834896073684 \t 1.4877388542122816\n",
      "5 \t 0.01 \t 200 \t 0.7712803860287301 \t 0.7694901183361298 \t 1.8616302894307382\n",
      "5 \t 0.01 \t 300 \t 0.7787627835888593 \t 0.7754341672076086 \t 1.6242307263462492\n",
      "5 \t 0.01 \t 400 \t 0.784709872207509 \t 0.7806357561940465 \t 1.555808812656549\n",
      "5 \t 0.01 \t 500 \t 0.7893874374811852 \t 0.7851748362890583 \t 1.5232539376287553\n",
      "5 \t 0.01 \t 600 \t 0.789325004167664 \t 0.7852833844223767 \t 1.513546111815503\n",
      "5 \t 0.01 \t 700 \t 0.791906060384845 \t 0.7876121277634514 \t 1.5007085382836547\n",
      "5 \t 0.01 \t 800 \t 0.7918350680147929 \t 0.786870396176935 \t 1.4943914812287917\n",
      "5 \t 0.01 \t 900 \t 0.7931939450307851 \t 0.7891116135040307 \t 1.4883694072823794\n",
      "5 \t 0.01 \t 1000 \t 0.7918168794343284 \t 0.7876180350737083 \t 1.4856419451389649\n",
      "6 \t 0.1 \t 200 \t 0.7664072478361844 \t 0.7617902226433292 \t 1.5282352228576461\n",
      "6 \t 0.1 \t 300 \t 0.7720552507439647 \t 0.7654381081101166 \t 1.5133060903425668\n",
      "6 \t 0.1 \t 400 \t 0.7798619525268998 \t 0.7742769008516441 \t 1.4914806734506656\n",
      "6 \t 0.1 \t 500 \t 0.7755801872113686 \t 0.7703324360411319 \t 1.50351727104192\n",
      "6 \t 0.1 \t 600 \t 0.7697929398689227 \t 0.7638400593025096 \t 1.5188878752160346\n",
      "6 \t 0.1 \t 700 \t 0.7772116151468855 \t 0.7746207386774251 \t 1.5000033080114115\n",
      "6 \t 0.1 \t 800 \t 0.7684942801458392 \t 0.7618224296225387 \t 1.5227514555887662\n",
      "6 \t 0.1 \t 900 \t 0.7777604659202548 \t 0.7678032171084928 \t 1.4980323029942042\n",
      "6 \t 0.1 \t 1000 \t 0.7752569436767064 \t 0.7696023572310129 \t 1.5036670100808294\n",
      "6 \t 0.05 \t 200 \t 0.7858733366422876 \t 0.7819211221683238 \t 1.489809039274881\n",
      "6 \t 0.05 \t 300 \t 0.7893770067884723 \t 0.7847876242400205 \t 1.4745051323622689\n",
      "6 \t 0.05 \t 400 \t 0.7869333876983353 \t 0.7815961391821304 \t 1.4772678766676757\n",
      "6 \t 0.05 \t 500 \t 0.7918690358903989 \t 0.7868992044296952 \t 1.46079011565836\n",
      "6 \t 0.05 \t 600 \t 0.7856700588835961 \t 0.7793936025989093 \t 1.479212283487577\n",
      "6 \t 0.05 \t 700 \t 0.7879189574446169 \t 0.7832378049791693 \t 1.471100434813736\n",
      "6 \t 0.05 \t 800 \t 0.783332285016128 \t 0.7768907642572809 \t 1.4822267308308759\n",
      "6 \t 0.05 \t 900 \t 0.7877107510468322 \t 0.7841498774984389 \t 1.4706421290478242\n",
      "6 \t 0.05 \t 1000 \t 0.7872277473753126 \t 0.7824932731125042 \t 1.4717999807329605\n",
      "6 \t 0.01 \t 200 \t 0.7844113453292609 \t 0.778807241364358 \t 1.827237446434978\n",
      "6 \t 0.01 \t 300 \t 0.7903981693331643 \t 0.7848705693497935 \t 1.58037506422158\n",
      "6 \t 0.01 \t 400 \t 0.7940706283946131 \t 0.7878297271782608 \t 1.5185665751852313\n",
      "6 \t 0.01 \t 500 \t 0.7950832481070886 \t 0.7882298058345708 \t 1.4967295924091355\n",
      "6 \t 0.01 \t 600 \t 0.7973151881379398 \t 0.7909794564540602 \t 1.4811552136642028\n",
      "6 \t 0.01 \t 700 \t 0.7972608197186652 \t 0.7915384660329012 \t 1.4744015957451198\n",
      "6 \t 0.01 \t 800 \t 0.7968226878908754 \t 0.7908385711505337 \t 1.471851686859101\n",
      "6 \t 0.01 \t 900 \t 0.7974555141796204 \t 0.7916758716879203 \t 1.4663508614536842\n",
      "6 \t 0.01 \t 1000 \t 0.7973732745876827 \t 0.7894728495723495 \t 1.4633819518768205\n",
      "7 \t 0.1 \t 200 \t 0.7785933622875214 \t 0.7726336975354974 \t 1.495760723571714\n",
      "7 \t 0.1 \t 300 \t 0.7821667199734936 \t 0.7770564926327103 \t 1.4851565659495025\n",
      "7 \t 0.1 \t 400 \t 0.7767436050916939 \t 0.7693233379739421 \t 1.4996908112446994\n",
      "7 \t 0.1 \t 500 \t 0.7827634305447405 \t 0.7789399535399946 \t 1.4831211621074725\n",
      "7 \t 0.1 \t 600 \t 0.7761184090168061 \t 0.7711079121259657 \t 1.5031280803101592\n",
      "7 \t 0.1 \t 700 \t 0.780549613341462 \t 0.7754641892912437 \t 1.4909427534194404\n",
      "7 \t 0.1 \t 800 \t 0.7768105488935002 \t 0.7688277712888204 \t 1.5018043824327119\n",
      "7 \t 0.1 \t 900 \t 0.7817337896999723 \t 0.7753422397493628 \t 1.486496877676381\n",
      "7 \t 0.1 \t 1000 \t 0.7703746380261117 \t 0.7679585065383996 \t 1.5174259808468389\n",
      "7 \t 0.05 \t 200 \t 0.7884068026038749 \t 0.7829265787428893 \t 1.4781525049742967\n",
      "7 \t 0.05 \t 300 \t 0.7907217846081978 \t 0.7849103830024846 \t 1.4692652527808678\n",
      "7 \t 0.05 \t 400 \t 0.7932281790906334 \t 0.7859348876004394 \t 1.457094853436128\n",
      "7 \t 0.05 \t 500 \t 0.7946925546023621 \t 0.7901826978678895 \t 1.4514156470054371\n",
      "7 \t 0.05 \t 600 \t 0.7937125282305064 \t 0.7886719639612046 \t 1.4573676629312282\n",
      "7 \t 0.05 \t 700 \t 0.7866789749620449 \t 0.7806964477377828 \t 1.4743130330186671\n",
      "7 \t 0.05 \t 800 \t 0.7907040355544599 \t 0.7841701889350761 \t 1.4635100253969955\n",
      "7 \t 0.05 \t 900 \t 0.8011751524529404 \t 0.7923748764276464 \t 1.4349382695460438\n",
      "7 \t 0.05 \t 1000 \t 0.7933474809327346 \t 0.7857694515735577 \t 1.4568319222145107\n",
      "7 \t 0.01 \t 200 \t 0.7910961642765385 \t 0.7826705413503803 \t 1.7981283852537249\n",
      "7 \t 0.01 \t 300 \t 0.7955748258361213 \t 0.7874630693320349 \t 1.559548399885351\n",
      "7 \t 0.01 \t 400 \t 0.7979796241274079 \t 0.7907311066570912 \t 1.4967229889942493\n",
      "7 \t 0.01 \t 500 \t 0.800283872033565 \t 0.7927497883238203 \t 1.4745166839747865\n",
      "7 \t 0.01 \t 600 \t 0.7986264383904518 \t 0.790748019367279 \t 1.4704897107723451\n",
      "7 \t 0.01 \t 700 \t 0.8007831595952777 \t 0.7924687460152919 \t 1.4587144531424623\n",
      "7 \t 0.01 \t 800 \t 0.8045947051300366 \t 0.7970030517088631 \t 1.4456826275079433\n",
      "7 \t 0.01 \t 900 \t 0.8029141321514646 \t 0.7952544878727899 \t 1.4464900749552112\n",
      "7 \t 0.01 \t 1000 \t 0.8010688758818739 \t 0.7946608436529903 \t 1.4489712235211822\n",
      "8 \t 0.1 \t 200 \t 0.7814930910230069 \t 0.7737495317976045 \t 1.4891494402513727\n",
      "8 \t 0.1 \t 300 \t 0.7822767423667838 \t 0.7742925188088992 \t 1.4853089053804285\n",
      "8 \t 0.1 \t 400 \t 0.7768405959286466 \t 0.7713441236141876 \t 1.499842322490549\n",
      "8 \t 0.1 \t 500 \t 0.7754695808540126 \t 0.7655965535002976 \t 1.5028948017167132\n",
      "8 \t 0.1 \t 600 \t 0.7807728177248503 \t 0.7769150408747756 \t 1.4889270567696733\n",
      "8 \t 0.1 \t 700 \t 0.7746253035987677 \t 0.7653908496280606 \t 1.5075334277218673\n",
      "8 \t 0.1 \t 800 \t 0.774602244424283 \t 0.7666877874566771 \t 1.5063948265708742\n",
      "8 \t 0.1 \t 900 \t 0.7764010962317619 \t 0.7704602119712115 \t 1.504027704371751\n",
      "8 \t 0.1 \t 1000 \t 0.7780122197802789 \t 0.7744541201593543 \t 1.4979395193392961\n",
      "8 \t 0.05 \t 200 \t 0.7965972560259758 \t 0.7873332703504976 \t 1.453796702282683\n",
      "8 \t 0.05 \t 300 \t 0.79426438624862 \t 0.7896504734903511 \t 1.4556990892784216\n",
      "8 \t 0.05 \t 400 \t 0.7922466970044094 \t 0.7856808419197028 \t 1.4622794898133824\n",
      "8 \t 0.05 \t 500 \t 0.7964447019947534 \t 0.7925216690414301 \t 1.4484204089930401\n",
      "8 \t 0.05 \t 600 \t 0.7914389012053922 \t 0.7861342482124423 \t 1.4622370567622702\n",
      "8 \t 0.05 \t 700 \t 0.7936442405593457 \t 0.7860389220277471 \t 1.4554519049992627\n",
      "8 \t 0.05 \t 800 \t 0.7897437278369359 \t 0.782275560783744 \t 1.4686027160585269\n",
      "8 \t 0.05 \t 900 \t 0.7954693384774735 \t 0.7904120309811546 \t 1.451439580999251\n",
      "8 \t 0.05 \t 1000 \t 0.7950661893484761 \t 0.7898203288907546 \t 1.4533639669891332\n",
      "8 \t 0.01 \t 200 \t 0.798703248486123 \t 0.7899875947852918 \t 1.7758139460164308\n",
      "8 \t 0.01 \t 300 \t 0.7980759366537122 \t 0.7896717559916879 \t 1.545075441529732\n",
      "8 \t 0.01 \t 400 \t 0.8033843970399104 \t 0.7950564715960928 \t 1.4782701374635268\n",
      "8 \t 0.01 \t 500 \t 0.8043264877670155 \t 0.7961684215994008 \t 1.457364642026381\n",
      "8 \t 0.01 \t 600 \t 0.8036216496766146 \t 0.794447371263155 \t 1.4495513277041892\n",
      "8 \t 0.01 \t 700 \t 0.806408767042055 \t 0.7986663236954721 \t 1.4396117440142038\n",
      "8 \t 0.01 \t 800 \t 0.8056657171571782 \t 0.7983603573929827 \t 1.4393434319964304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 \t 0.01 \t 900 \t 0.8036668695849988 \t 0.7947611870053011 \t 1.440696472003507\n",
      "8 \t 0.01 \t 1000 \t 0.8052892846108154 \t 0.7993057698002781 \t 1.4344484577350622\n",
      "9 \t 0.1 \t 200 \t 0.7778730758189456 \t 0.7762126374086002 \t 1.496489183273469\n",
      "9 \t 0.1 \t 300 \t 0.7910625969588805 \t 0.783651478541276 \t 1.4616336522176097\n",
      "9 \t 0.1 \t 400 \t 0.7763337914580598 \t 0.7672336876620708 \t 1.5018079566826077\n",
      "9 \t 0.1 \t 500 \t 0.7826079806853565 \t 0.7739171213803752 \t 1.486919304772582\n",
      "9 \t 0.1 \t 600 \t 0.7797699854398112 \t 0.7705719653337446 \t 1.491564097329889\n",
      "9 \t 0.1 \t 700 \t 0.7837396925211559 \t 0.7761712053147428 \t 1.4834781734795146\n",
      "9 \t 0.1 \t 800 \t 0.7804978892915044 \t 0.7761741185088421 \t 1.4909701167861926\n",
      "9 \t 0.1 \t 900 \t 0.7806529717733868 \t 0.7731121896663146 \t 1.4906692888091655\n",
      "9 \t 0.1 \t 1000 \t 0.7858387978197967 \t 0.7780094307914291 \t 1.4733586144222373\n",
      "9 \t 0.05 \t 200 \t 0.7944906545050048 \t 0.7883298254986482 \t 1.457138784298727\n",
      "9 \t 0.05 \t 300 \t 0.7990363670914158 \t 0.7915787652179421 \t 1.4424659987766109\n",
      "9 \t 0.05 \t 400 \t 0.7969245303809578 \t 0.7905806725506834 \t 1.448459842725885\n",
      "9 \t 0.05 \t 500 \t 0.794108034601279 \t 0.7873312472990397 \t 1.4552708747139287\n",
      "9 \t 0.05 \t 600 \t 0.7950275075141551 \t 0.7883311202515813 \t 1.454046386143911\n",
      "9 \t 0.05 \t 700 \t 0.7958644033147927 \t 0.7882976994414972 \t 1.4494537384298323\n",
      "9 \t 0.05 \t 800 \t 0.796336557781052 \t 0.7891071627908234 \t 1.4502846739222497\n",
      "9 \t 0.05 \t 900 \t 0.7940059048055075 \t 0.7862010898326107 \t 1.4552094404369245\n",
      "9 \t 0.05 \t 1000 \t 0.7946434183443836 \t 0.789652739307984 \t 1.454793104957316\n",
      "9 \t 0.01 \t 200 \t 0.8036821172558174 \t 0.7933455365171361 \t 1.7562204000184027\n",
      "9 \t 0.01 \t 300 \t 0.8031875599824927 \t 0.7928669634642607 \t 1.5240496950983997\n",
      "9 \t 0.01 \t 400 \t 0.807137586241726 \t 0.7979549378808238 \t 1.463679622390436\n",
      "9 \t 0.01 \t 500 \t 0.8069102381742439 \t 0.79886094124572 \t 1.4464767882895682\n",
      "9 \t 0.01 \t 600 \t 0.8069560960258289 \t 0.7991411743336653 \t 1.4385637418208457\n",
      "9 \t 0.01 \t 700 \t 0.8055976025056528 \t 0.7965267444736204 \t 1.4380918319763605\n",
      "9 \t 0.01 \t 800 \t 0.8066022436633776 \t 0.7998594385232703 \t 1.4323635177731817\n",
      "9 \t 0.01 \t 900 \t 0.8082196656916997 \t 0.8005441200586745 \t 1.4260458541554297\n",
      "9 \t 0.01 \t 1000 \t 0.808814217056438 \t 0.8011570237283532 \t 1.4239109632792997\n",
      "10 \t 0.1 \t 200 \t 0.7841290063690866 \t 0.7743008537809055 \t 1.4808371525040147\n",
      "10 \t 0.1 \t 300 \t 0.7814476351060053 \t 0.7722761029598028 \t 1.4889248866805538\n",
      "10 \t 0.1 \t 400 \t 0.7793020607601538 \t 0.7708321297512277 \t 1.4933858543858887\n",
      "10 \t 0.1 \t 500 \t 0.7820978041658461 \t 0.7742264864093138 \t 1.4844476517765546\n",
      "10 \t 0.1 \t 600 \t 0.7851236922688491 \t 0.7798695861459187 \t 1.4789697684964533\n",
      "10 \t 0.1 \t 700 \t 0.7840844691375957 \t 0.7794509763382547 \t 1.4800834335864503\n",
      "10 \t 0.1 \t 800 \t 0.7808165876136959 \t 0.7737348849050494 \t 1.4876775034269294\n",
      "10 \t 0.1 \t 900 \t 0.7873931452790573 \t 0.7775665443662705 \t 1.4732984672927494\n",
      "10 \t 0.1 \t 1000 \t 0.7867463186205719 \t 0.7775820004794086 \t 1.4725006526498228\n",
      "10 \t 0.05 \t 200 \t 0.7990383045163775 \t 0.7948179942902381 \t 1.4457292884422492\n",
      "10 \t 0.05 \t 300 \t 0.7942794795679828 \t 0.7875691581504861 \t 1.4579899241780687\n",
      "10 \t 0.05 \t 400 \t 0.7955071371050084 \t 0.7898221900980957 \t 1.4540445327519549\n",
      "10 \t 0.05 \t 500 \t 0.7959308689991251 \t 0.7896220698478824 \t 1.4526581175433808\n",
      "10 \t 0.05 \t 600 \t 0.800301697871087 \t 0.7929172160624743 \t 1.4401799779734548\n",
      "10 \t 0.05 \t 700 \t 0.7970863529855663 \t 0.7911089317473646 \t 1.4484385284771644\n",
      "10 \t 0.05 \t 800 \t 0.7972805451601654 \t 0.7933867258448186 \t 1.4474100296603185\n",
      "10 \t 0.05 \t 900 \t 0.7962603756668397 \t 0.7907250375027177 \t 1.4506725765595747\n",
      "10 \t 0.05 \t 1000 \t 0.7950702552346469 \t 0.7904486077515133 \t 1.4539661785935323\n",
      "10 \t 0.01 \t 200 \t 0.8017221409532889 \t 0.7919213082907901 \t 1.7583599721076169\n",
      "10 \t 0.01 \t 300 \t 0.8018085378919949 \t 0.7925363159339849 \t 1.5245442528858257\n",
      "10 \t 0.01 \t 400 \t 0.8053690131727903 \t 0.7950050051670045 \t 1.4634075260367698\n",
      "10 \t 0.01 \t 500 \t 0.8073107525461737 \t 0.7990376750210801 \t 1.4403875530729064\n",
      "10 \t 0.01 \t 600 \t 0.8063770551509715 \t 0.7982112504837867 \t 1.4372311570365013\n",
      "10 \t 0.01 \t 700 \t 0.8080715136716178 \t 0.800155208646412 \t 1.429974364047211\n",
      "10 \t 0.01 \t 800 \t 0.8071601955670189 \t 0.8017924237302436 \t 1.4297688905423618\n",
      "10 \t 0.01 \t 900 \t 0.8062449130044405 \t 0.7984479150600796 \t 1.4298160021256812\n",
      "10 \t 0.01 \t 1000 \t 0.8081695223905759 \t 0.8016944271176241 \t 1.424666791360858\n"
     ]
    }
   ],
   "source": [
    "for md in [5,6,7,8,9,10]:                                   # maximum depth\n",
    "    for lr in [0.1,0.05,0.01]:                              # learning rate\n",
    "        for nt in [200,300,400,500,600,700,800,900,1000]:   # number of trees\n",
    "            ppreds = []; rps = 0; rss = 0; rmses = 0\n",
    "            for seed in np.random.randint(1, 5000, size=10):\n",
    "                RGR = xgb.XGBRegressor(reg_lambda=0.001, max_depth=md, learning_rate=lr, subsample=0.5, n_estimators=nt,colsample_bytree=0.56, silent=1, random_state=seed)\n",
    "                RGR.fit(train.loc[:,'CC':], train.loc[:, 'pbindaff'], eval_metric='mae')\n",
    "                preds = RGR.predict(test.loc[:,'CC':])\n",
    "                ppreds.append(preds)\n",
    "                rps += pearsonr(test['pbindaff'], preds)[0]\n",
    "                rss += spearmanr(test['pbindaff'], preds)[0]\n",
    "                rmses += rmse(test['pbindaff'], preds)\n",
    "            print(md, lr, nt, rps/10, rss/10, rmses/10, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Table 1: Performance of XGBoost trained on different structural similarity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\t1105\t0.8064938692264734\t0.799103626498607\t1.4290335124018092\n",
      "0.999\t964\t0.7681999182337883\t0.7762874810811381\t1.555279280180205\n",
      "0.998\t867\t0.742447577504785\t0.7557403277195742\t1.6168420513847503\n",
      "0.997\t810\t0.7276670475637596\t0.7458781946285935\t1.6656254319916255\n",
      "0.996\t793\t0.7301134740176046\t0.7472549216067087\t1.6623155007957098\n",
      "0.995\t779\t0.7195822990314565\t0.7343843491537468\t1.6835759460493729\n",
      "0.99\t710\t0.7042166654415805\t0.7161143332817667\t1.7120752990654626\n",
      "0.985\t685\t0.6884181578886613\t0.6993049605623745\t1.7452188576300283\n",
      "0.98\t645\t0.6832728753996881\t0.6965559573193515\t1.7516980700453035\n",
      "0.975\t605\t0.6670286901399132\t0.6901103535304355\t1.7863613357775758\n",
      "0.97\t582\t0.6654912538419893\t0.6843574425606967\t1.7944710556141552\n",
      "0.965\t567\t0.668695368953687\t0.6861759230551542\t1.7872570149133602\n",
      "0.96\t563\t0.6689946140997365\t0.687385869671082\t1.7886647264740199\n",
      "0.955\t548\t0.6665662837406676\t0.6837101470162341\t1.7910572411232295\n",
      "0.95\t540\t0.6596826512953975\t0.6765360828583653\t1.805498115660423\n",
      "0.9\t510\t0.6621140337227991\t0.6734153236794428\t1.809804158336861\n",
      "0.85\t476\t0.6518306931194322\t0.6708119801413869\t1.8472714221474142\n",
      "0.8\t462\t0.651313988245478\t0.6706074901000244\t1.8461104848616174\n",
      "0.75\t443\t0.6559885121783828\t0.6743709322660858\t1.8431658245230793\n",
      "0.7\t416\t0.6469343947805728\t0.6681471225446735\t1.858950456831798\n",
      "0.65\t400\t0.6420685517320683\t0.6629733031185758\t1.8657097960374238\n",
      "0.6\t371\t0.6415364640174464\t0.6590784435298107\t1.8701936479507881\n",
      "0.55\t330\t0.6430070181982523\t0.6578693061344663\t1.867883722769189\n",
      "0.5\t294\t0.6278342546599764\t0.6343051264413357\t1.911005695406003\n",
      "0.45\t222\t0.6113896958239929\t0.6315241589852784\t1.965531485825256\n",
      "0.4\t116\t0.6357224061774865\t0.6518376995958903\t1.884455151657783\n",
      "0.35\t43\t0.5202472602063763\t0.5189470908205049\t2.042942633860511\n",
      "0.3\t9\t0.25602707059140706\t0.24623908571342817\t2.406747029594233\n",
      "0.25\t1\tnan\tnan\t2.5489955660485846\n"
     ]
    }
   ],
   "source": [
    "cutoffs = {}\n",
    "for co in co_structure:\n",
    "    cutoffs[co] = SS[SS.max(axis=1)<=co].index\n",
    "    if len(cutoffs[co])>0:                            # to exclude excepions with empty training sets\n",
    "        rp = 0; rs = 0; rmses = 0\n",
    "        for seed in np.random.randint(0, 9999, size=10):\n",
    "            RGR = xgb.XGBRegressor(reg_lambda=0.001, max_depth=9, learning_rate=0.01, subsample=0.5, n_estimators=1000,colsample_bytree=0.58, silent=1, random_state=seed)\n",
    "            RGR.fit(train.loc[cutoffs[co],'CC':], train.loc[cutoffs[co], 'pbindaff'], eval_metric='rmse')\n",
    "            preds = RGR.predict(test.loc[:,'CC':])\n",
    "            if len(cutoffs[co])==1:                  # to exclude exceptions with Rp and Rs calculations on 1 example\n",
    "                rp = np.nan\n",
    "                rs = np.nan\n",
    "            else:\n",
    "                rp += pearsonr(test['pbindaff'], preds)[0]\n",
    "                rs += spearmanr(test['pbindaff'], preds)[0]\n",
    "            rmses += rmse(test['pbindaff'], preds)\n",
    "        print(co, len(cutoffs[co]), rp/10, rs/10, rmses/10, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Table 3: Performance of XGBoost trained on different structural similarity levels, requiring certain similarity level in training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\t1105\t0.8089740249363953\t0.8007750716131058\t1.4227737996088554\n",
      "0.05\t1105\t0.8073400480761783\t0.7996738842435537\t1.42726749391563\n",
      "0.1\t1105\t0.8070595772566245\t0.7986052275414444\t1.4265910361770977\n",
      "0.15\t1105\t0.8070351192906617\t0.8003902063037591\t1.4275872490498025\n",
      "0.2\t1105\t0.8085592954250742\t0.8016470067914513\t1.4226888238571378\n",
      "0.25\t1104\t0.80658766792171\t0.800232731978278\t1.4291598097644096\n",
      "0.3\t1096\t0.8069550984858112\t0.7977867009215867\t1.4283006113392676\n",
      "0.35\t1062\t0.8048633508803655\t0.7999430310095098\t1.432060813808477\n",
      "0.4\t989\t0.8055551482516478\t0.802468122917175\t1.4286998553527348\n",
      "0.45\t883\t0.7973055322660748\t0.7900712681935897\t1.4520167218398703\n",
      "0.5\t811\t0.7919868378354602\t0.7874493935041798\t1.4675212331178638\n",
      "0.55\t775\t0.7883267423672481\t0.7828528587477641\t1.4776392632908089\n",
      "0.6\t734\t0.7938797256523636\t0.7869318969412545\t1.4627177349796943\n",
      "0.65\t705\t0.7971988492033675\t0.7919265682245804\t1.4559761713196449\n",
      "0.7\t689\t0.8004396706818078\t0.7929662548298131\t1.446672582186558\n",
      "0.75\t662\t0.7953634215442025\t0.7881025154368412\t1.4640557554210385\n",
      "0.8\t643\t0.7972795452364345\t0.7858946379977713\t1.4519883352701406\n",
      "0.85\t629\t0.7986656577087229\t0.7866164627579422\t1.4501386090721526\n",
      "0.9\t595\t0.8038116040981655\t0.7934657866957926\t1.435821602009288\n",
      "0.95\t565\t0.8029033439989988\t0.7944811157614722\t1.4418270250121745\n",
      "0.955\t557\t0.7979034916490019\t0.7885079349489998\t1.4539159860825381\n",
      "0.96\t542\t0.7979505128050517\t0.786986195642384\t1.453847321880197\n",
      "0.965\t538\t0.7947227355249928\t0.7852552728150236\t1.4585556817171637\n",
      "0.97\t523\t0.7923814090832708\t0.7818686037524774\t1.4655785142892852\n",
      "0.975\t500\t0.7916636037271394\t0.7808743144219596\t1.4661095593001614\n",
      "0.98\t460\t0.7797254465144673\t0.7709270513256313\t1.497481306002857\n",
      "0.985\t420\t0.769136303833702\t0.7604723260016092\t1.5247614766847182\n",
      "0.99\t395\t0.7560680667150195\t0.7531382789344513\t1.5634069934913462\n",
      "0.995\t326\t0.7582930907526861\t0.7553675197969163\t1.5579143165858702\n",
      "0.996\t312\t0.7582387986900548\t0.7524760128092005\t1.555919063067615\n",
      "0.997\t295\t0.7477136840288898\t0.7422745735277044\t1.5803648863221222\n",
      "0.998\t238\t0.7074159063115197\t0.7148962944600075\t1.6807369565894548\n",
      "0.999\t141\t0.6602178204569435\t0.6662300922775264\t1.7900589979762878\n"
     ]
    }
   ],
   "source": [
    "cutoffs = {}\n",
    "for co in reversed(co_structure):\n",
    "    cutoffs[co] = SS[SS.max(axis=1)>co].index\n",
    "    if len(cutoffs[co])>0:\n",
    "        rp = 0; rs = 0; rmses = 0\n",
    "        for seed in np.random.randint(0, 9999, size=10):\n",
    "            RGR = xgb.XGBRegressor(reg_lambda=0.001, max_depth=9, learning_rate=0.01, subsample=0.5, n_estimators=1000,colsample_bytree=0.58, silent=1, random_state=seed)\n",
    "            RGR.fit(train.loc[cutoffs[co],'CC':], train.loc[cutoffs[co], 'pbindaff'], eval_metric='rmse')\n",
    "            preds = RGR.predict(test.loc[:,'CC':])\n",
    "            if len(cutoffs[co])==1:\n",
    "                rp = np.nan\n",
    "                rs = np.nan\n",
    "            else:\n",
    "                rp += pearsonr(test['pbindaff'], preds)[0]\n",
    "                rs += spearmanr(test['pbindaff'], preds)[0]\n",
    "            rmses += rmse(test['pbindaff'], preds)\n",
    "        print(co, len(cutoffs[co]), rp/10, rs/10, rmses/10, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_sequence = [1.00000, 0.99900, 0.99800, 0.99700, 0.99600, 0.99500, 0.99000, 0.98500, 0.98000, 0.97500, 0.97000,\n",
    "                0.96500, 0.96000, 0.95500, 0.95000, 0.90000, 0.85000, 0.80000, 0.75000, 0.70000, 0.65000, 0.60000,\n",
    "                0.55000, 0.50000, 0.45000, 0.40000, 0.35000, 0.30000, 0.25000, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
    "\n",
    "# file paths should be changed to actual placement\n",
    "SS = ps.read_excel('Sequence_Similarity.xls')\n",
    "train = ps.read_table('../../rawdata/training.tsv', index_col=0)\n",
    "test = ps.read_table('../../rawdata/test.tsv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Table 2: Performance of XGBoost trained on different sequence similarity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\t1105\t0.8072835931702025\t0.8000551080602764\t1.4268917604872946\n",
      "0.999\t786\t0.7226311399064146\t0.7434743239642845\t1.67904413413993\n",
      "0.998\t785\t0.7197256137875907\t0.7410986950983276\t1.684377546036909\n",
      "0.997\t781\t0.7191205683626324\t0.7390265239510521\t1.6843233818635515\n",
      "0.996\t746\t0.7105173335795325\t0.7319819350864873\t1.7044499414373255\n",
      "0.995\t726\t0.7007204083195392\t0.7203364416743583\t1.728174577400417\n",
      "0.99\t692\t0.6890337465228481\t0.7067707487404695\t1.7426718900147122\n",
      "0.985\t678\t0.6832122597424439\t0.7008695076378391\t1.7580321153995295\n",
      "0.98\t670\t0.6761684549949436\t0.6959876417038046\t1.7723993209188738\n",
      "0.975\t640\t0.6635637367925572\t0.6857047948316435\t1.7927937867924828\n",
      "0.97\t638\t0.6617818969738469\t0.6837662260026465\t1.7937654138624635\n",
      "0.965\t606\t0.6738569374419148\t0.6958763738736211\t1.772332282038494\n",
      "0.96\t606\t0.6751963210590801\t0.6985998057462166\t1.7691584377220182\n",
      "0.955\t584\t0.6612576192239019\t0.6852623939388348\t1.8015410285822735\n",
      "0.95\t584\t0.6642815387095273\t0.6873261491920453\t1.7946529275339536\n",
      "0.9\t565\t0.6627156927194011\t0.6806588998854041\t1.801193216122129\n",
      "0.85\t558\t0.6734322404944052\t0.6923716395279932\t1.7777954610001205\n",
      "0.8\t554\t0.6715085449144123\t0.6853259177546123\t1.7801303566312885\n",
      "0.75\t553\t0.667894949876696\t0.6820282629562125\t1.7859415567293806\n",
      "0.7\t552\t0.6697164302671931\t0.6820113502460247\t1.782475020110282\n",
      "0.65\t545\t0.6586491032620369\t0.675869851552257\t1.8026143960352154\n",
      "0.6\t542\t0.6520177886022837\t0.6642264621136438\t1.8180469432048398\n",
      "0.55\t535\t0.6524924434225007\t0.6690993456992054\t1.819833201027097\n",
      "0.5\t522\t0.6511105196907312\t0.6680692078968541\t1.8222292965925913\n",
      "0.45\t508\t0.6557552406152322\t0.6729445191441651\t1.8249965185968975\n",
      "0.4\t451\t0.6476282616841953\t0.6647940494306661\t1.8502260752329263\n",
      "0.35\t350\t0.655001904170098\t0.6716579393390131\t1.8559722626436734\n",
      "0.3\t181\t0.6148209619136665\t0.6318887937800464\t1.9166824711968509\n",
      "0.25\t56\t0.6037714421587944\t0.6051933350404124\t1.898053631719031\n",
      "0.2\t14\t0.44723061014995996\t0.45322098122608806\t2.2218239886635516\n",
      "0.15\t1\tnan\tnan\t2.548325923235685\n"
     ]
    }
   ],
   "source": [
    "cutoffs = {}\n",
    "for co in co_sequence:\n",
    "    cutoffs[co] = SS[SS.max(axis=1)<=co].index\n",
    "    if len(cutoffs[co])>0:\n",
    "        rp = 0; rs = 0; rmses = 0\n",
    "        for seed in np.random.randint(0, 9999, size=10):\n",
    "            RGR = xgb.XGBRegressor(reg_lambda=0.001, max_depth=9, learning_rate=0.01, subsample=0.5, n_estimators=1000,colsample_bytree=0.58, silent=1, random_state=seed)\n",
    "            RGR.fit(train.loc[cutoffs[co],'CC':], train.loc[cutoffs[co], 'pbindaff'], eval_metric='rmse')\n",
    "            preds = RGR.predict(test.loc[:,'CC':])\n",
    "            if len(cutoffs[co])==1:\n",
    "                rp = np.nan\n",
    "                rs = np.nan\n",
    "            else:\n",
    "                rp += pearsonr(test['pbindaff'], preds)[0]\n",
    "                rs += spearmanr(test['pbindaff'], preds)[0]\n",
    "            rmses += rmse(test['pbindaff'], preds)\n",
    "        print(co, len(cutoffs[co]), rp/10, rs/10, rmses/10, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for Table 4: Performance of XGBoost trained on different sequence similarity levels, requiring certain similarity level in training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\t1105\t0.8057633012707986\t0.7968840962831397\t1.431953828014297\n",
      "0.05\t1105\t0.8066569860002468\t0.7992921748944812\t1.428947073329904\n",
      "0.1\t1105\t0.8078242260446562\t0.7991280649602184\t1.4251922253690044\n",
      "0.15\t1104\t0.8083069794311598\t0.801598129868229\t1.4250906291133845\n",
      "0.2\t1091\t0.8075754921141527\t0.8010325656026647\t1.4254447538827\n",
      "0.25\t1049\t0.8022187031079966\t0.7961806408302065\t1.440886331699782\n",
      "0.3\t924\t0.7972391663246878\t0.7909774334026024\t1.4534634722607598\n",
      "0.35\t755\t0.7942255101399464\t0.7838236806813708\t1.4581407669118487\n",
      "0.4\t654\t0.7971676254903616\t0.7891413118994323\t1.4527479180168301\n",
      "0.45\t597\t0.7972236137465698\t0.789285272241175\t1.4561166001591925\n",
      "0.5\t583\t0.7984201106079734\t0.7897160203575864\t1.4497844092265688\n",
      "0.55\t570\t0.8017255824038131\t0.7947299510907914\t1.4414070148113023\n",
      "0.6\t563\t0.8028966785572471\t0.7942208704219308\t1.4407821762808222\n",
      "0.65\t560\t0.8014417323594569\t0.7921204574763036\t1.4461813503483318\n",
      "0.7\t553\t0.8004784085876709\t0.7922845674105665\t1.4462948528678918\n",
      "0.75\t552\t0.8001344800838245\t0.7930570493792428\t1.4467784226815144\n",
      "0.8\t551\t0.7990130688614491\t0.7918613450455785\t1.4503381650153035\n",
      "0.85\t547\t0.8037104906581514\t0.791129890560468\t1.4422343450931927\n",
      "0.9\t540\t0.802897371187815\t0.7926254920422482\t1.4471118041762678\n",
      "0.95\t521\t0.8007780913232236\t0.7911611264749776\t1.4549699760805308\n",
      "0.955\t521\t0.800325523762041\t0.7902378057896022\t1.4555046231660653\n",
      "0.96\t499\t0.8009633767970982\t0.791205876373226\t1.4542587862754508\n",
      "0.965\t499\t0.801102589225227\t0.7906243704621736\t1.4525522077373458\n",
      "0.97\t467\t0.799627851651193\t0.7901218444800366\t1.4568061496394669\n",
      "0.975\t465\t0.7975956701451214\t0.7882311005875039\t1.4616056661326484\n",
      "0.98\t435\t0.7954887313808496\t0.7874063429691561\t1.4619283707304365\n",
      "0.985\t427\t0.7860358715561478\t0.7769648079406392\t1.4809241441970677\n",
      "0.99\t413\t0.7788899141467425\t0.7677276359060264\t1.5018610644433716\n",
      "0.995\t379\t0.7704323427430185\t0.7565965640186064\t1.5211837419930307\n",
      "0.996\t359\t0.7632620896867417\t0.745831826289179\t1.5418877444803212\n",
      "0.997\t324\t0.7662898437630281\t0.7449925836223927\t1.5303687455970485\n",
      "0.998\t320\t0.7676748477967842\t0.7471765890542597\t1.528308117341705\n",
      "0.999\t319\t0.7664641284985835\t0.7445553617413163\t1.5309988878716625\n"
     ]
    }
   ],
   "source": [
    "cutoffs = {}\n",
    "for co in reversed(co_sequence):\n",
    "    cutoffs[co] = SS[SS.max(axis=1)>co].index\n",
    "    if len(cutoffs[co])>0:\n",
    "        rp = 0; rs = 0; rmses = 0\n",
    "        for seed in np.random.randint(0, 9999, size=10):\n",
    "            RGR = xgb.XGBRegressor(reg_lambda=0.001, max_depth=9, learning_rate=0.01, subsample=0.5, n_estimators=1000,colsample_bytree=0.58, silent=1, random_state=seed)\n",
    "            RGR.fit(train.loc[cutoffs[co],'CC':], train.loc[cutoffs[co], 'pbindaff'], eval_metric='rmse')\n",
    "            preds = RGR.predict(test.loc[:,'CC':])\n",
    "            if len(cutoffs[co])==1:\n",
    "                rp = np.nan\n",
    "                rs = np.nan\n",
    "            else:\n",
    "                rp += pearsonr(test['pbindaff'], preds)[0]\n",
    "                rs += spearmanr(test['pbindaff'], preds)[0]\n",
    "            rmses += rmse(test['pbindaff'], preds)\n",
    "        print(co, len(cutoffs[co]), rp/10, rs/10, rmses/10, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
